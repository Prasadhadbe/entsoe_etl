name: Deploy Airflow DAGs to Azure File Share

on:
  push:
    branches:
      - main
    paths:
      - "dags/**"

env:
  ACR_NAME: airflowacrcluster
  AKS_RESOURCE_GROUP: airflow-rg
  AKS_CLUSTER_NAME: airflow-aks
  IMAGE_NAME: airflow
  IMAGE_TAG: latest

jobs:
  deploy:
    name: Upload DAGs to Azure File Share
    runs-on: ubuntu-latest
    environment: etl-workflow

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Log in to Azure
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Upload DAGs using Azure CLI
        run: |
          echo "ðŸ“‚ Uploading DAGs using az storage file upload-batch..."

          az storage file upload-batch \
            --account-name ${{ secrets.AZURE_STORAGE_ACCOUNT }} \
            --account-key ${{ secrets.AZURE_STORAGE_KEY }} \
            --destination "pvc-a97254bb-1499-4e7e-bc74-cd016e8fa2bf/dags" \
            --source "./dags"

          echo "âœ… DAGs successfully uploaded to Azure File Share."

      - name: Restart Airflow Deployments
        run: |
          echo "ðŸ”„ Restarting Airflow pods to reload DAGs..."
          az aks get-credentials --resource-group $AKS_RESOURCE_GROUP --name $AKS_CLUSTER_NAME --overwrite-existing
          kubectl rollout restart deployment airflow-webserver -n airflow
          kubectl rollout restart deployment airflow-scheduler -n airflow
          echo "âœ… Restart complete!"
