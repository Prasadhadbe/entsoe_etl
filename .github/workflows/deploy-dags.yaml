name: Deploy Airflow DAGs to Azure File Share

on:
  push:
    branches:
      - main
    paths:
      - "dags/**"

env:
  ACR_NAME: airflowacrcluster
  AKS_RESOURCE_GROUP: airflow-rg
  AKS_CLUSTER_NAME: airflow-aks
  IMAGE_NAME: airflow
  IMAGE_TAG: latest

jobs:
  deploy:
    name: Upload DAGs to Azure File Share
    runs-on: ubuntu-latest
    environment: etl-workflow

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Log in to Azure
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Upload DAGs
        run: |
          echo "üîç Verifying file share access..."
          az storage share exists \
            --account-name f314a19b0d8b1437a879f40 \
            --name pvc-a97254bb-1499-4e7e-bc74-cd016e8fa2bf \
            --account-key ${{ secrets.AZURE_STORAGE_KEY }} \
            --output tsv

          echo "üßπ Clearing existing DAGs..."
          az storage file delete-batch \
            --account-name f314a19b0d8b1437a879f40 \
            --account-key ${{ secrets.AZURE_STORAGE_KEY }} \
            --source "pvc-a97254bb-1499-4e7e-bc74-cd016e8fa2bf/dags" \
            --pattern "*" \
            --auth-mode key

          echo "üöÄ Uploading new DAGs..."
          az storage file upload-batch \
            --account-name f314a19b0d8b1437a879f40 \
            --account-key ${{ secrets.AZURE_STORAGE_KEY }} \
            --destination "pvc-a97254bb-1499-4e7e-bc74-cd016e8fa2bf/dags" \
            --source "dags" \
            --auth-mode key \
            --verbose

      - name: Restart Airflow Deployments
        run: |
          echo "üîÑ Restarting Airflow pods to reload DAGs..."
          az aks get-credentials --resource-group $AKS_RESOURCE_GROUP --name $AKS_CLUSTER_NAME --overwrite-existing
          kubectl rollout restart deployment airflow-webserver -n airflow
          kubectl rollout restart deployment airflow-scheduler -n airflow
          echo "‚úÖ Restart complete!"
